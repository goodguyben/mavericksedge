{
  "name": "Pinecone Assistant",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.3,
      "position": [
        208,
        -512
      ],
      "id": "3a5cf144-268b-49e8-82f9-071a50997b00",
      "name": "When chat message received",
      "webhookId": "5d4af093-6fa7-4fae-a655-a192e4389ee5"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        240,
        -304
      ],
      "id": "ed03aa73-5b43-446f-8a0c-7903e8e76cf8",
      "name": "OpenRouter Chat Model",
      "credentials": {
        "openRouterApi": {
          "id": "td3utRybtI5wRRtH",
          "name": "OpenRouter account 2"
        }
      }
    },
    {
      "parameters": {
        "toolDescription": "Use this to search through the knowledge base",
        "method": "POST",
        "url": "https://prod-1-data.ke.pinecone.io/assistant/chat/[PINECONE ASSISTANT NAME]",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Api-Key",
              "value": "$PINECONE_API_KEY"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"content\": \"{{ $fromAI(\"searchQuery\") }}\"\n    }\n  ],\n  \"stream\": false,\n  \"model\": \"gpt-4.1\",\n  \"include_highlights\": true\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        432,
        -304
      ],
      "id": "eb6acd39-30a8-460c-aa7d-19a4d95df4bc",
      "name": "Pinecone"
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        560,
        -304
      ],
      "id": "f75c5327-ebe0-4f9a-be14-675c5c352423",
      "name": "Calculator"
    },
    {
      "parameters": {
        "formTitle": "Drop in PDF",
        "formFields": {
          "values": [
            {
              "fieldLabel": "PDF",
              "fieldType": "file",
              "multipleFiles": false,
              "requiredField": true
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.formTrigger",
      "typeVersion": 2.3,
      "position": [
        1616,
        -368
      ],
      "id": "d9994f7d-f037-46da-a4de-94b00fc251c7",
      "name": "On form submission",
      "webhookId": "38efbb20-d74a-4f22-b567-da767c53fa8f"
    },
    {
      "parameters": {
        "mode": "insert",
        "pineconeIndex": {
          "__rl": true,
          "value": "earnings",
          "mode": "list",
          "cachedResultName": "earnings"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        1936,
        -512
      ],
      "id": "9dad609a-f18f-4284-90fd-c496278075ce",
      "name": "Pinecone Vector Store",
      "credentials": {
        "pineconeApi": {
          "id": "kRQGVexSgzWhzJz2",
          "name": "PineconeApi account 4"
        }
      }
    },
    {
      "parameters": {
        "dataType": "binary",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1.1,
      "position": [
        2080,
        -400
      ],
      "id": "6e053b7a-819e-4fa8-b0e7-fb5afe35b2e4",
      "name": "Default Data Loader"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1920,
        -400
      ],
      "id": "f8c19952-4807-4986-bc7e-02fc5367fdb1",
      "name": "Embeddings OpenAI",
      "credentials": {
        "openAiApi": {
          "id": "yWkFMwOwuEEU2cnu",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "=# Overview\nYou are an AI agent specialized in analyzing earnings report data. \n\nUse your Pinecone tool to search through earnings reports from Tesla, Nike, and Nvidia.\n\nWhen answering the user's question, always cite your sources as far as: what document you got it from, what page it was from, what section, and an exact text based quote from the original source"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        2448,
        -480
      ],
      "id": "103eaade-aa31-42ce-a2b2-3eaad9a70632",
      "name": "Pinecone Vector"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        2320,
        -272
      ],
      "id": "24639f13-b137-4186-bbe7-94aa8f187b4b",
      "name": "OpenRouter Chat Model1",
      "credentials": {
        "openRouterApi": {
          "id": "td3utRybtI5wRRtH",
          "name": "OpenRouter account 2"
        }
      }
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "Use this to search through the knowledge base",
        "pineconeIndex": {
          "__rl": true,
          "value": "earnings",
          "mode": "list",
          "cachedResultName": "earnings"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "typeVersion": 1.3,
      "position": [
        2464,
        -272
      ],
      "id": "f77ab030-8611-45ac-a5fa-54f5b85589c2",
      "name": "Pinecone Store",
      "credentials": {
        "pineconeApi": {
          "id": "kRQGVexSgzWhzJz2",
          "name": "PineconeApi account 4"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        2464,
        -144
      ],
      "id": "73874220-7b56-4948-8485-58d5633b16be",
      "name": "Embeddings OpenAI1",
      "credentials": {
        "openAiApi": {
          "id": "yWkFMwOwuEEU2cnu",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        2736,
        -272
      ],
      "id": "04e1194e-7ef6-4212-8cf7-59df2dd30d8b",
      "name": "Calculator1"
    },
    {
      "parameters": {
        "mode": "insert",
        "tableName": {
          "__rl": true,
          "value": "documents",
          "mode": "list",
          "cachedResultName": "documents"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "typeVersion": 1.3,
      "position": [
        1936,
        -224
      ],
      "id": "5e863ed3-8cda-43df-a766-85034bbbfca7",
      "name": "Supabase Vector Store",
      "credentials": {
        "supabaseApi": {
          "id": "r1eLu64ie9Tz6yOK",
          "name": "Demo 2.22.25"
        }
      }
    },
    {
      "parameters": {
        "dataType": "binary",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "typeVersion": 1.1,
      "position": [
        2080,
        -112
      ],
      "id": "3ceebef2-e914-4d5d-9bba-2338d216ccb8",
      "name": "Default Data Loader1"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        1920,
        -112
      ],
      "id": "104dfa4b-2b92-4a64-8a75-ad468c529066",
      "name": "Embeddings OpenAI2",
      "credentials": {
        "openAiApi": {
          "id": "yWkFMwOwuEEU2cnu",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "=# Overview\nYou are an AI agent specialized in analyzing earnings report data. \n\nUse your Pinecone tool to search through earnings reports from Tesla, Nike, and Nvidia.\n\nWhen answering the user's question, always cite your sources as far as: what document you got it from, what page it was from, what section, and an exact text based quote from the original source"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        2976,
        -480
      ],
      "id": "83341850-ad4c-4c31-b480-68eb506a5e5a",
      "name": "Supabase Vector"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        2864,
        -272
      ],
      "id": "7ca5d2a9-6fde-4fac-b046-e683a2feeab2",
      "name": "OpenRouter Chat Model2",
      "credentials": {
        "openRouterApi": {
          "id": "td3utRybtI5wRRtH",
          "name": "OpenRouter account 2"
        }
      }
    },
    {
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolDescription": "knowledge ",
        "tableName": {
          "__rl": true,
          "value": "documents",
          "mode": "list",
          "cachedResultName": "documents"
        },
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "typeVersion": 1.3,
      "position": [
        2992,
        -272
      ],
      "id": "958bd916-1835-43f9-b862-a5dde532c8ae",
      "name": "Supabase Store",
      "credentials": {
        "supabaseApi": {
          "id": "r1eLu64ie9Tz6yOK",
          "name": "Demo 2.22.25"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "typeVersion": 1.2,
      "position": [
        2992,
        -144
      ],
      "id": "f5749ff0-56a2-4ec7-b07e-01a03a911e93",
      "name": "Embeddings OpenAI3",
      "credentials": {
        "openAiApi": {
          "id": "yWkFMwOwuEEU2cnu",
          "name": "OpenAi account 2"
        }
      }
    },
    {
      "parameters": {},
      "type": "@n8n/n8n-nodes-langchain.toolCalculator",
      "typeVersion": 1,
      "position": [
        3264,
        -272
      ],
      "id": "edc53c2f-0bd3-4e2a-a1a9-490c5fa7e6d2",
      "name": "Calculator2"
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "=# Overview\nYou are an AI agent specialized in analyzing earnings report data. \n\nUse your Pinecone tool to search through earnings reports from Tesla, Nike, and Nvidia.\n\nWhen answering the user's question, always cite your sources as far as: what document you got it from, what page it was from, what section, and an exact text based quote from the original source"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        368,
        -512
      ],
      "id": "720e1e3b-fdb9-4e46-a96d-fa59e44c8010",
      "name": "Pinecone Assistant"
    },
    {
      "parameters": {
        "content": "# üõ†Ô∏è Setup Guide  \n## **Author:** [Nate Herk](https://www.youtube.com/@nateherk)\n\nFollow these steps to set up your Pinecone Assistant workflow inside n8n:\n\n### ‚úÖ Step 1: Create a Pinecone Account  \nGo to [pinecone.io](https://www.pinecone.io/) and sign up for an account.\n\n### ‚úÖ Step 2: Create a Pinecone Assistant  \nInside your Pinecone dashboard, create an assistant and upload the files you want included in your knowledge base.\n\n### ‚úÖ Step 3: Copy the cURL Command  \nAfter setting up your assistant, grab the **cURL version** (not Python) of the API request to interact with your assistant.\n\n### ‚úÖ Step 4: Insert into Pinecone HTTP Request Tool  \nPaste the cURL command into the **Pinecone HTTP Request Tool** and link it to your Pinecone Assistant agent.\n\n### ‚úÖ Step 5: Connect Your Pinecone API Key  \nGrab your API key from the Pinecone dashboard and connect it via the HTTP Request node to authorize your requests.\n\n### ‚úÖ Step 6: Connect Your [OpenRouter](https://openrouter.ai/) API Key (or another model)  \nHook up the chat model you want to use‚ÄîClaude, GPT-4, Mistral, etc.‚Äîthrough your preferred API key.\n\n### üß† Step 7: Refine the System Prompts  \nTailor the assistant‚Äôs system prompts to match your **use case** and **knowledge base**.  \n‚ö†Ô∏è The default prompt is trained for analyzing **Tesla, NVIDIA, and Nike earnings reports**, so be sure to adjust accordingly.\n\n### üß™ Step 8: Run & Test  \nTest the setup and confirm you're getting responses **with source documents**. Tweak body params like:\n- `include_highlights`\n- `model`\n- `temperature`\n\n---\n\n### üåÄ Optional Next Steps  \nExplore other vector store flows:\n- Use the **Ingestion flow** for Pinecone or Supabase\n- Try out the **Pinecone Vector Store** or **Supabase Vector Store** AI agents  \nGreat for comparing the Pinecone Assistant vs traditional chunked retrieval approaches.\n",
        "height": 1024,
        "width": 928
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        -864,
        -624
      ],
      "id": "bcd1234c-ad31-4e9d-9f61-9bc3eabbbbcb",
      "name": "Sticky Note"
    },
    {
      "parameters": {
        "content": "# Pinecone Assistant Agent\n",
        "height": 464,
        "width": 688,
        "color": 5
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        80,
        -624
      ],
      "id": "9995ea3a-5a9d-4288-9465-4c680fdfb114",
      "name": "Sticky Note1"
    },
    {
      "parameters": {
        "content": "# Pinecone Assistant API Settings\n\nHere are the most useful parameters to tweak when working with the Pinecone Assistant API.\n\nüìò **Full docs:** [Pinecone Assistant API Guide](https://docs.pinecone.io/guides/assistant)\n\n## Model Selection\n\nYou can choose which model the assistant uses by setting the `model` parameter in your request body.\n\n**Supported models:**\n- `gpt-4o` (default)\n- `gpt-4-1`\n- `o1-mini-1`\n- `claude-3-5-sonnet`\n- `claude-3-5-sonnet`\n- `gemini-1.5-pro`\n\nUse this to compare quality, speed, or cost depending on your use case.\n\n## Citation Highlights\n\nSet `include_highlights` to `true` to show which exact parts of your documents were used to generate the assistant's response.\n\nThis improves traceability and is helpful when validating or debugging outputs.\n\n## Temperature Control\n\nThe `temperature` parameter adjusts the randomness of the assistant's output:\n\n- **Lower values** (e.g. 0.2) = more focused and consistent responses\n- **Higher values** (e.g. 1.0) = more creative or exploratory responses\n\nUse these settings together to tune your assistant's behavior to fit your specific workflow or user experience.",
        "height": 896,
        "width": 688,
        "color": 4
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        784,
        -624
      ],
      "id": "6c00afd3-d0fd-4f27-8116-bc58c0c79516",
      "name": "Sticky Note2"
    },
    {
      "parameters": {
        "content": "# Ingestion flow for Pinecone/Supabase Vector Store",
        "height": 704,
        "width": 1936,
        "color": 6
      },
      "type": "n8n-nodes-base.stickyNote",
      "typeVersion": 1,
      "position": [
        1488,
        -624
      ],
      "id": "b38fc761-94f4-43d6-a34b-ebb1180fb01c",
      "name": "Sticky Note3"
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "Pinecone Assistant",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Pinecone Assistant",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone": {
      "ai_tool": [
        [
          {
            "node": "Pinecone Assistant",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Calculator": {
      "ai_tool": [
        [
          {
            "node": "Pinecone Assistant",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "On form submission": {
      "main": [
        [
          {
            "node": "Supabase Vector Store",
            "type": "main",
            "index": 0
          },
          {
            "node": "Pinecone Vector Store",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Pinecone Vector",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Pinecone Store": {
      "ai_tool": [
        [
          {
            "node": "Pinecone Vector",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI1": {
      "ai_embedding": [
        [
          {
            "node": "Pinecone Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Calculator1": {
      "ai_tool": [
        [
          {
            "node": "Pinecone Vector",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader1": {
      "ai_document": [
        [
          {
            "node": "Supabase Vector Store",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI2": {
      "ai_embedding": [
        [
          {
            "node": "Supabase Vector Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Supabase Vector",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Supabase Store": {
      "ai_tool": [
        [
          {
            "node": "Supabase Vector",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Embeddings OpenAI3": {
      "ai_embedding": [
        [
          {
            "node": "Supabase Store",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Calculator2": {
      "ai_tool": [
        [
          {
            "node": "Supabase Vector",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "d383e608-326b-47b3-889f-479fd616c5f6",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "95e5a8c2e51c83e33b232ea792bbe3f063c094c33d9806a5565cb31759e1ad39"
  },
  "id": "NHjMDwmwYicvsKbl",
  "tags": []
}